{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG Pipeline Testing & Fine-tuning Notebook\n",
    "\n",
    "This notebook allows you to test the complete RAG pipeline:\n",
    "1. PDF Extraction\n",
    "2. Chunking (namespace-specific strategies)\n",
    "3. Pinecone Ingestion\n",
    "4. RAG Search & Retrieval\n",
    "5. Agent Routing\n",
    "6. End-to-End Chat with Citations\n",
    "\n",
    "**Setup**: Run from `backend/` directory:\n",
    "```bash\n",
    "cd backend\n",
    "jupyter notebook notebooks/test_rag_pipeline.ipynb\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'current_dir' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/0m/rb0qcj9s5v32nxlmn24w42880000gn/T/ipykernel_19084/363936254.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Ensure we're in backend directory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mbackend_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcwd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_dir\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mbackend_dir\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'backend'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mbackend_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackend_dir\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m'backend'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'current_dir' is not defined"
     ]
    }
   ],
   "source": [
    "# Add backend to path\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Ensure we're in backend directory\n",
    "current_dir = Path.cwd()\n",
    "os.chdir(current_dir.parent)\n",
    "if backend_dir.name != 'backend':\n",
    "    backend_dir = backend_dir.parent / 'backend'\n",
    "sys.path.insert(0, str(backend_dir))\n",
    "\n",
    "print(f\"Working directory: {backend_dir}\")\n",
    "print(f\"Python path: {sys.path[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core imports\n",
    "import os\n",
    "import logging\n",
    "from dotenv import load_dotenv\n",
    "from pprint import pprint\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv(backend_dir / \".env\")\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(name)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Verify environment variables\n",
    "print(\"Environment Check:\")\n",
    "print(f\"âœ“ OPENAI_API_KEY: {'Set' if os.getenv('OPENAI_API_KEY') else 'âŒ Missing'}\")\n",
    "print(f\"âœ“ PINECONE_API_KEY: {'Set' if os.getenv('PINECONE_API_KEY') else 'âŒ Missing'}\")\n",
    "print(f\"âœ“ PINECONE_INDEX: {os.getenv('PINECONE_INDEX', 'Not set')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import RAG services and agents\n",
    "from app.services.rag_service import (\n",
    "    get_rag_service,\n",
    "    NAMESPACE_CLINICAL_SAFETY,\n",
    "    NAMESPACE_CULTURAL_DIET,\n",
    "    NAMESPACE_LIFESTYLE_PATTERNS,\n",
    ")\n",
    "from app.agents.router_agent import RouterState, route_intent\n",
    "from app.agents.clinical_safety_agent import ClinicalSafetyState, check_clinical_safety\n",
    "from app.agents.lifestyle_analyst_agent import LifestyleState, analyze_lifestyle\n",
    "from app.schemas.patient_context import PatientContext\n",
    "from app.schemas.enhanced_patient_context import EnhancedPatientContext\n",
    "\n",
    "print(\"âœ“ Imports successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. PDF Extraction Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import PDF extraction utilities\n",
    "try:\n",
    "    import pdfplumber\n",
    "    PDFPLUMBER_AVAILABLE = True\n",
    "    print(\"âœ“ pdfplumber available\")\n",
    "except ImportError:\n",
    "    PDFPLUMBER_AVAILABLE = False\n",
    "    print(\"âŒ pdfplumber not available\")\n",
    "\n",
    "try:\n",
    "    import fitz  # PyMuPDF\n",
    "    PYMUPDF_AVAILABLE = True\n",
    "    print(\"âœ“ PyMuPDF available\")\n",
    "except ImportError:\n",
    "    PYMUPDF_AVAILABLE = False\n",
    "    print(\"âŒ PyMuPDF not available\")\n",
    "\n",
    "def extract_text_from_pdf(pdf_path: Path) -> str:\n",
    "    \"\"\"Extract text from PDF file.\"\"\"\n",
    "    text_content = []\n",
    "    \n",
    "    if PDFPLUMBER_AVAILABLE:\n",
    "        try:\n",
    "            with pdfplumber.open(pdf_path) as pdf:\n",
    "                for page_num, page in enumerate(pdf.pages, 1):\n",
    "                    text = page.extract_text()\n",
    "                    if text:\n",
    "                        text_content.append(f\"Page {page_num}:\\n{text}\\n\")\n",
    "            print(f\"âœ“ Extracted {len(text_content)} pages using pdfplumber\")\n",
    "            return \"\\n\".join(text_content)\n",
    "        except Exception as e:\n",
    "            print(f\"pdfplumber failed: {e}\")\n",
    "    \n",
    "    if PYMUPDF_AVAILABLE:\n",
    "        try:\n",
    "            doc = fitz.open(pdf_path)\n",
    "            for page_num, page in enumerate(doc, 1):\n",
    "                text = page.get_text()\n",
    "                if text:\n",
    "                    text_content.append(f\"Page {page_num}:\\n{text}\\n\")\n",
    "            doc.close()\n",
    "            print(f\"âœ“ Extracted {len(text_content)} pages using PyMuPDF\")\n",
    "            return \"\\n\".join(text_content)\n",
    "        except Exception as e:\n",
    "            print(f\"PyMuPDF failed: {e}\")\n",
    "    \n",
    "    raise RuntimeError(\"Could not extract text. Install pdfplumber or pymupdf.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test PDF extraction on a sample file\n",
    "rag_docs_dir = backend_dir / \"rag_docs\"\n",
    "clinical_docs_dir = rag_docs_dir / \"clinical_safety_docs\"\n",
    "\n",
    "# List available PDFs\n",
    "if clinical_docs_dir.exists():\n",
    "    pdf_files = list(clinical_docs_dir.glob(\"*.pdf\"))\n",
    "    print(f\"Found {len(pdf_files)} PDFs in clinical_safety_docs/\")\n",
    "    for pdf in pdf_files[:5]:  # Show first 5\n",
    "        print(f\"  - {pdf.name} ({pdf.stat().st_size / 1024:.0f} KB)\")\n",
    "    \n",
    "    if pdf_files:\n",
    "        # Test extraction on first small PDF\n",
    "        test_pdf = min(pdf_files, key=lambda p: p.stat().st_size)  # Smallest file\n",
    "        print(f\"\\nTesting extraction on: {test_pdf.name}\")\n",
    "        \n",
    "        extracted_text = extract_text_from_pdf(test_pdf)\n",
    "        print(f\"\\nExtracted {len(extracted_text)} characters\")\n",
    "        print(\"\\nFirst 500 characters:\")\n",
    "        print(\"=\" * 80)\n",
    "        print(extracted_text[:500])\n",
    "        print(\"=\" * 80)\n",
    "else:\n",
    "    print(\"âŒ rag_docs/clinical_safety_docs/ directory not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Chunking Strategy Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import chunking functions\n",
    "import re\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "def chunk_with_headers(text: str, source: str, min_chunk_size: int = 200, max_chunk_size: int = 1000) -> List[Dict[str, Any]]:\n",
    "    \"\"\"Chunk text preserving headers (for clinical safety documents).\"\"\"\n",
    "    chunks = []\n",
    "    lines = text.split('\\n')\n",
    "    current_header_stack = []\n",
    "    current_chunk = []\n",
    "    current_chunk_size = 0\n",
    "    \n",
    "    for line in lines:\n",
    "        line_stripped = line.strip()\n",
    "        if not line_stripped:\n",
    "            continue\n",
    "        \n",
    "        # Detect headers\n",
    "        is_header = (\n",
    "            line_stripped.isupper() and len(line_stripped) > 3 and len(line_stripped) < 100\n",
    "            or re.match(r'^\\d+\\.?\\s+[A-Z]', line_stripped)\n",
    "            or re.match(r'^[A-Z][A-Z\\s]{3,}', line_stripped)\n",
    "            or line_stripped.endswith(':') and len(line_stripped) < 80\n",
    "        )\n",
    "        \n",
    "        if is_header:\n",
    "            if current_chunk_size >= min_chunk_size:\n",
    "                header_path = \" > \".join(current_header_stack) if current_header_stack else \"Introduction\"\n",
    "                chunk_text = \"\\n\".join(current_chunk)\n",
    "                chunks.append({\n",
    "                    \"content\": f\"Header: {header_path}\\n{chunk_text}\",\n",
    "                    \"metadata\": {\n",
    "                        \"source\": source,\n",
    "                        \"header_path\": header_path,\n",
    "                        \"tags\": [h.lower().replace(\" \", \"_\") for h in current_header_stack],\n",
    "                    }\n",
    "                })\n",
    "            \n",
    "            if len(current_header_stack) < 3:\n",
    "                current_header_stack.append(line_stripped)\n",
    "            else:\n",
    "                current_header_stack[-1] = line_stripped\n",
    "            \n",
    "            current_chunk = [line_stripped]\n",
    "            current_chunk_size = len(line_stripped)\n",
    "        else:\n",
    "            current_chunk.append(line_stripped)\n",
    "            current_chunk_size += len(line_stripped) + 1\n",
    "            \n",
    "            if current_chunk_size >= max_chunk_size:\n",
    "                header_path = \" > \".join(current_header_stack) if current_header_stack else \"Introduction\"\n",
    "                chunk_text = \"\\n\".join(current_chunk)\n",
    "                chunks.append({\n",
    "                    \"content\": f\"Header: {header_path}\\n{chunk_text}\",\n",
    "                    \"metadata\": {\n",
    "                        \"source\": source,\n",
    "                        \"header_path\": header_path,\n",
    "                        \"tags\": [h.lower().replace(\" \", \"_\") for h in current_header_stack],\n",
    "                    }\n",
    "                })\n",
    "                current_chunk = []\n",
    "                current_chunk_size = 0\n",
    "    \n",
    "    if current_chunk_size >= min_chunk_size:\n",
    "        header_path = \" > \".join(current_header_stack) if current_header_stack else \"Introduction\"\n",
    "        chunk_text = \"\\n\".join(current_chunk)\n",
    "        chunks.append({\n",
    "            \"content\": f\"Header: {header_path}\\n{chunk_text}\",\n",
    "            \"metadata\": {\n",
    "                \"source\": source,\n",
    "                \"header_path\": header_path,\n",
    "                \"tags\": [h.lower().replace(\" \", \"_\") for h in current_header_stack],\n",
    "            }\n",
    "        })\n",
    "    \n",
    "    return chunks\n",
    "\n",
    "print(\"âœ“ Chunking function loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test chunking on extracted text\n",
    "if 'extracted_text' in locals():\n",
    "    chunks = chunk_with_headers(extracted_text, source=test_pdf.name)\n",
    "    \n",
    "    print(f\"Created {len(chunks)} chunks from {len(extracted_text)} characters\")\n",
    "    print(f\"Average chunk size: {sum(len(c['content']) for c in chunks) / len(chunks):.0f} chars\")\n",
    "    \n",
    "    # Show first 3 chunks\n",
    "    print(\"\\nFirst 3 chunks:\")\n",
    "    for i, chunk in enumerate(chunks[:3], 1):\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"Chunk {i}:\")\n",
    "        print(f\"Source: {chunk['metadata']['source']}\")\n",
    "        print(f\"Header: {chunk['metadata']['header_path']}\")\n",
    "        print(f\"Tags: {chunk['metadata'].get('tags', [])}\")\n",
    "        print(f\"Length: {len(chunk['content'])} chars\")\n",
    "        print(f\"\\nContent preview (first 300 chars):\")\n",
    "        print(chunk['content'][:300])\n",
    "else:\n",
    "    print(\"No extracted text available. Run PDF extraction cell first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Pinecone Connection & Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize RAG service\n",
    "rag = get_rag_service()\n",
    "\n",
    "if rag.is_available():\n",
    "    print(\"âœ“ RAG service initialized successfully\")\n",
    "    print(f\"  Index: {rag.index_name}\")\n",
    "    \n",
    "    # Get index stats\n",
    "    try:\n",
    "        stats = rag.index.describe_index_stats()\n",
    "        print(f\"\\nIndex Statistics:\")\n",
    "        print(f\"  Total vectors: {stats.get('total_vector_count', 'N/A')}\")\n",
    "        print(f\"  Dimensions: {stats.get('dimension', 'N/A')}\")\n",
    "        \n",
    "        namespaces = stats.get('namespaces', {})\n",
    "        if namespaces:\n",
    "            print(f\"\\n  Namespaces:\")\n",
    "            for ns, ns_stats in namespaces.items():\n",
    "                print(f\"    - {ns}: {ns_stats.get('vector_count', 0)} vectors\")\n",
    "    except Exception as e:\n",
    "        print(f\"Could not fetch index stats: {e}\")\n",
    "else:\n",
    "    print(\"âŒ RAG service not available. Check PINECONE_API_KEY.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. RAG Search & Retrieval Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test RAG search on different namespaces\n",
    "if rag.is_available():\n",
    "    test_queries = [\n",
    "        {\n",
    "            \"query\": \"metformin kidney disease contraindication\",\n",
    "            \"namespace\": NAMESPACE_CLINICAL_SAFETY,\n",
    "            \"top_k\": 3\n",
    "        },\n",
    "        {\n",
    "            \"query\": \"glucose target Type 2 Diabetes elderly\",\n",
    "            \"namespace\": NAMESPACE_LIFESTYLE_PATTERNS,\n",
    "            \"top_k\": 3\n",
    "        },\n",
    "        {\n",
    "            \"query\": \"Hainanese Chicken Rice nutritional carbs\",\n",
    "            \"namespace\": NAMESPACE_CULTURAL_DIET,\n",
    "            \"top_k\": 2\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    for test in test_queries:\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"Query: {test['query']}\")\n",
    "        print(f\"Namespace: {test['namespace']}\")\n",
    "        print(f\"{'='*80}\")\n",
    "        \n",
    "        results = rag.search(test['query'], namespace=test['namespace'], top_k=test['top_k'])\n",
    "        \n",
    "        if results:\n",
    "            print(f\"\\nFound {len(results)} results:\")\n",
    "            for i, result in enumerate(results, 1):\n",
    "                print(f\"\\nResult {i}:\")\n",
    "                print(f\"  Score: {result.get('score', 'N/A')}\")\n",
    "                print(f\"  Source: {result.get('metadata', {}).get('source', 'Unknown')}\")\n",
    "                print(f\"  Tags: {result.get('metadata', {}).get('tags', [])}\")\n",
    "                print(f\"  Content preview: {result.get('content', '')[:200]}...\")\n",
    "        else:\n",
    "            print(\"âŒ No results found\")\n",
    "else:\n",
    "    print(\"RAG service not available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test formatted context for LLM (with citations)\n",
    "if rag.is_available():\n",
    "    query = \"MOH guidelines for metformin use in elderly patients\"\n",
    "    \n",
    "    print(f\"Query: {query}\")\n",
    "    print(f\"Namespace: {NAMESPACE_CLINICAL_SAFETY}\")\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    \n",
    "    context = rag.get_context_for_llm(\n",
    "        query=query,\n",
    "        namespace=NAMESPACE_CLINICAL_SAFETY,\n",
    "        top_k=3,\n",
    "        include_citations=True\n",
    "    )\n",
    "    \n",
    "    if context:\n",
    "        print(\"\\nFormatted Context (with mandatory citations):\")\n",
    "        print(\"=\"*80)\n",
    "        print(context)\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        # Check for citation markers\n",
    "        source_count = context.count(\"Source:\")\n",
    "        citation_instruction_count = context.count(\"you MUST cite\")\n",
    "        print(f\"\\nCitation Analysis:\")\n",
    "        print(f\"  Sources mentioned: {source_count}\")\n",
    "        print(f\"  Citation instructions: {citation_instruction_count}\")\n",
    "    else:\n",
    "        print(\"âŒ No context returned\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Agent Routing Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create test patient context\n",
    "test_patient = PatientContext(\n",
    "    user_id=\"test-user-123\",\n",
    "    first_name=\"John\",\n",
    "    last_name=\"Doe\",\n",
    "    age=65,\n",
    "    sex=\"Male\",\n",
    "    ethnicity=\"Chinese\",\n",
    "    height=170.0,\n",
    "    activity_level=\"moderate\",\n",
    "    location=\"Singapore\",\n",
    "    conditions=[\"Type 2 Diabetes\", \"Hypertension\"],\n",
    "    medications=[\"Metformin 500mg\", \"Lisinopril 10mg\"]\n",
    ")\n",
    "\n",
    "print(\"Test patient created:\")\n",
    "print(f\"  Name: {test_patient.first_name} {test_patient.last_name}\")\n",
    "print(f\"  Age: {test_patient.age}\")\n",
    "print(f\"  Conditions: {test_patient.conditions}\")\n",
    "print(f\"  Medications: {test_patient.medications}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test router agent with different queries\n",
    "test_routing_queries = [\n",
    "    \"What are the side effects of metformin?\",  # Should route to clinical_safety\n",
    "    \"What do MOH guidelines say about diabetes management?\",  # Should route to clinical_safety\n",
    "    \"What was my average glucose this week?\",  # Should route to lifestyle_analyst\n",
    "    \"Did I take my medication today?\",  # Should route to lifestyle_analyst\n",
    "    \"Hello, how are you?\",  # Should route to unmatched\n",
    "]\n",
    "\n",
    "for query in test_routing_queries:\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Query: {query}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    state = RouterState(patient=test_patient, user_message=query)\n",
    "    decision = route_intent.invoke(input=state)\n",
    "    \n",
    "    print(f\"\\nRouting Decision:\")\n",
    "    print(f\"  Target Agent: {decision['target_agent']}\")\n",
    "    print(f\"  Intent: {decision['intent']}\")\n",
    "    print(f\"  Rationale: {decision['rationale']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Clinical Safety Agent Testing (with RAG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Clinical Safety Agent with RAG integration\n",
    "test_clinical_query = \"What do MOH guidelines say about metformin use in elderly patients with kidney disease?\"\n",
    "\n",
    "print(f\"Query: {test_clinical_query}\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Create agent state\n",
    "clinical_state = ClinicalSafetyState(\n",
    "    patient=test_patient,\n",
    "    user_message=test_clinical_query,\n",
    "    enhanced_context=None  # Can add enhanced context if needed\n",
    ")\n",
    "\n",
    "# Invoke agent\n",
    "result = check_clinical_safety.invoke(input=clinical_state)\n",
    "\n",
    "print(\"\\nClinical Safety Analysis:\")\n",
    "print(f\"  Is Safe: {result.get('is_safe', 'N/A')}\")\n",
    "print(f\"  Warnings ({len(result.get('warnings', []))}):\")\n",
    "for warning in result.get('warnings', []):\n",
    "    print(f\"    - {warning}\")\n",
    "print(f\"\\n  Rationale: {result.get('rationale', 'N/A')}\")\n",
    "\n",
    "# Check RAG context\n",
    "rag_context = result.get('rag_context', '')\n",
    "rag_citations = result.get('rag_citations', [])\n",
    "\n",
    "print(f\"\\n  RAG Context Length: {len(rag_context)} chars\")\n",
    "print(f\"  RAG Citations ({len(rag_citations)}): {rag_citations}\")\n",
    "\n",
    "if rag_context:\n",
    "    print(\"\\n  RAG Context Preview (first 500 chars):\")\n",
    "    print(\"  \" + \"-\"*78)\n",
    "    print(\"  \" + rag_context[:500])\n",
    "    print(\"  \" + \"-\"*78)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. End-to-End Chat Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate full chat flow: Router â†’ Agent â†’ LLM Response\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "from app.core.system_prompt_builder import build_system_prompt\n",
    "\n",
    "def test_full_chat_flow(user_query: str, patient: PatientContext):\n",
    "    \"\"\"Test complete chat flow with RAG citations.\"\"\"\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"User Query: {user_query}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    # Step 1: Router\n",
    "    router_state = RouterState(patient=patient, user_message=user_query)\n",
    "    routing_decision = route_intent.invoke(input=router_state)\n",
    "    print(f\"\\n[ROUTER] Target Agent: {routing_decision['target_agent']}\")\n",
    "    \n",
    "    # Step 2: Agent (Clinical Safety)\n",
    "    if routing_decision['target_agent'] == 'clinical_safety':\n",
    "        clinical_state = ClinicalSafetyState(\n",
    "            patient=patient,\n",
    "            user_message=user_query,\n",
    "            enhanced_context=None\n",
    "        )\n",
    "        agent_result = check_clinical_safety.invoke(input=clinical_state)\n",
    "        \n",
    "        rag_context = agent_result.get('rag_context', '')\n",
    "        rag_citations = agent_result.get('rag_citations', [])\n",
    "        agent_text = agent_result.get('rationale', '')\n",
    "        \n",
    "        print(f\"[AGENT] RAG Citations: {rag_citations}\")\n",
    "        print(f\"[AGENT] RAG Context Length: {len(rag_context)} chars\")\n",
    "        \n",
    "        # Step 3: Build System Prompt\n",
    "        patient_str = f\"{patient.first_name} {patient.last_name}, {patient.age}yo {patient.sex}\"\n",
    "        system_prompt = build_system_prompt(\n",
    "            patient_context_str=patient_str,\n",
    "            enhanced_context=None,\n",
    "            user_message=user_query,\n",
    "            agent_text=agent_text,\n",
    "            rag_context=rag_context\n",
    "        )\n",
    "        \n",
    "        # Step 4: LLM Call\n",
    "        llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.7)\n",
    "        messages = [\n",
    "            SystemMessage(content=system_prompt),\n",
    "            HumanMessage(content=user_query)\n",
    "        ]\n",
    "        \n",
    "        print(f\"\\n[LLM] Calling GPT-4o-mini...\")\n",
    "        response = llm.invoke(messages)\n",
    "        \n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(\"LLM RESPONSE:\")\n",
    "        print(f\"{'='*80}\")\n",
    "        print(response.content)\n",
    "        print(f\"{'='*80}\")\n",
    "        \n",
    "        # Step 5: Citation Validation\n",
    "        print(f\"\\n[VALIDATION] Citation Check:\")\n",
    "        citations_found = []\n",
    "        for citation in rag_citations:\n",
    "            clean_citation = citation.replace('.pdf', '').replace('_', ' ')\n",
    "            if clean_citation in response.content or citation in response.content:\n",
    "                citations_found.append(citation)\n",
    "                print(f\"  âœ“ Found citation: {citation}\")\n",
    "            else:\n",
    "                print(f\"  âŒ Missing citation: {citation}\")\n",
    "        \n",
    "        if citations_found:\n",
    "            print(f\"\\n  âœ“ SUCCESS: {len(citations_found)}/{len(rag_citations)} citations included\")\n",
    "        else:\n",
    "            print(f\"\\n  âŒ FAILURE: No citations found in response\")\n",
    "        \n",
    "        return response.content, citations_found\n",
    "    else:\n",
    "        print(f\"[INFO] Not a clinical safety query, skipping detailed flow\")\n",
    "        return None, []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test full chat flow with citation validation\n",
    "test_queries = [\n",
    "    \"What do MOH guidelines recommend for metformin dosing in elderly patients?\",\n",
    "    \"Are there any contraindications for metformin in patients with kidney disease?\",\n",
    "    \"What are the ADA recommendations for HbA1c targets?\"\n",
    "]\n",
    "\n",
    "for query in test_queries:\n",
    "    response, citations = test_full_chat_flow(query, test_patient)\n",
    "    print(\"\\n\" + \"#\"*80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Fine-tuning Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment with different RAG parameters\n",
    "print(\"RAG Parameter Tuning\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if rag.is_available():\n",
    "    query = \"metformin kidney disease contraindication\"\n",
    "    \n",
    "    # Test different top_k values\n",
    "    for top_k in [1, 3, 5]:\n",
    "        results = rag.search(query, namespace=NAMESPACE_CLINICAL_SAFETY, top_k=top_k)\n",
    "        print(f\"\\ntop_k={top_k}: {len(results)} results\")\n",
    "        if results:\n",
    "            avg_score = sum(r.get('score', 0) for r in results) / len(results)\n",
    "            print(f\"  Average score: {avg_score:.4f}\")\n",
    "            print(f\"  Min score: {min(r.get('score', 0) for r in results):.4f}\")\n",
    "            print(f\"  Max score: {max(r.get('score', 0) for r in results):.4f}\")\n",
    "else:\n",
    "    print(\"RAG service not available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Summary & Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"PIPELINE TESTING SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nâœ“ Components Tested:\")\n",
    "print(\"  1. PDF Extraction (pdfplumber/PyMuPDF)\")\n",
    "print(\"  2. Chunking Strategy (header-based for clinical docs)\")\n",
    "print(\"  3. Pinecone Connection & Stats\")\n",
    "print(\"  4. RAG Search & Retrieval\")\n",
    "print(\"  5. Agent Routing (LLM-based)\")\n",
    "print(\"  6. Clinical Safety Agent with RAG\")\n",
    "print(\"  7. End-to-End Chat with Citation Validation\")\n",
    "print(\"\\nâš ï¸ Known Issues:\")\n",
    "print(\"  - Citations may not appear consistently in LLM responses\")\n",
    "print(\"  - LLM relies on instructions, no programmatic enforcement\")\n",
    "print(\"  - rag_citations array collected but not fully utilized\")\n",
    "print(\"\\nðŸ’¡ Recommendations:\")\n",
    "print(\"  1. Add post-processing to validate citations in responses\")\n",
    "print(\"  2. Simplify citation instructions (fewer lines, clearer format)\")\n",
    "print(\"  3. Consider using JSON mode for structured output with citations\")\n",
    "print(\"  4. Monitor RAG retrieval scores (threshold: >0.7 for relevance)\")\n",
    "print(\"  5. Fine-tune chunk sizes based on retrieval quality\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
